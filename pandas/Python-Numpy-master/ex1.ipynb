{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ex1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMPQLtbe2TDuwdKZU5EwFV1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pyh3887/Python-Numpy/blob/master/ex1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--1I5kTL37lq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# numpy 의 함수 이용전에 수식으로 먼저 결과 확인 후 numpy함수와 비교\n",
        "\n",
        "!nvidia-smi\n",
        "!uname -r\n",
        "\n",
        "grades = [1,3,-2,4]\n",
        "\n",
        "def show_grades(grades):\n",
        "  for g in grades:\n",
        "    print(g, end = ' ')\n",
        "  \n",
        "show_grades(grades)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl-QoTvBjuHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "grades = [1,3,-2,4]\n",
        "def grades_sum(grades):\n",
        "  tot = 0 \n",
        "  for g in grades :\n",
        "    tot += g\n",
        "\n",
        "  return tot\n",
        "\n",
        "print(grades)\n",
        "grades_sum(grades)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErfSShiUkGIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def grades_ave(grades):\n",
        "  tot = grades_sum(grades)\n",
        "  ave = tot /len(grades)\n",
        "  return ave\n",
        "grades_ave(grades)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz8wlTgmkeZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def grades_vairance(grades): # 모분산 : 전체값들의 편차를 제곱해서 평균을 구함 \n",
        "  ave = grades_ave(grades)\n",
        "  vari = 0\n",
        "  for su in grades:\n",
        "    vari += (su - ave) ** 2\n",
        "\n",
        "  return vari/ len(grades)\n",
        "  #return vari/ len(grades-1) \n",
        "\n",
        "grades_vairance(grades)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FkCnDpXls4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def grades_std(grades): \n",
        "  return grades_vairance(grades) ** 0.5\n",
        "\n",
        "print('표준편차:' , grades_std(grades))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SOGX1iemLlK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "07240598-f9ed-4796-fd5a-2047bc6a999a"
      },
      "source": [
        "# numpy 로 결과 출력 \n",
        "import numpy\n",
        "print('합은' , numpy.sum(grades))\n",
        "print('평균은' , numpy.mean(grades))\n",
        "print('평균은' , numpy.average(grades))\n",
        "print('분산' , numpy.var(grades))\n",
        "print('표준편차는' , numpy.std(grades))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "합은 6\n",
            "평균은 1.5\n",
            "평균은 1.5\n",
            "분산 5.25\n",
            "표준편차는 2.29128784747792\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}